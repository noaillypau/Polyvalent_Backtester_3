{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing trade order 2019-09-29 00:00:00...\n",
      "Processing trade order 2019-09-30 00:00:00...\n",
      "Processing trade order 2019-10-01 00:00:00...\n",
      "Processing trade order 2019-10-02 00:00:00...\n",
      "Processing trade order 2019-10-03 00:00:00...\n",
      "Processing trade order 2019-10-04 00:00:00...\n",
      "Processing trade order 2019-10-05 00:00:00...\n",
      "Processing trade order 2019-10-06 00:00:00...\n",
      "Processing trade order 2019-10-07 00:00:00...\n",
      "Processing trade order 2019-10-08 00:00:00...\n",
      "Processing trade order 2019-10-09 00:00:00...\n",
      "Processing trade order 2019-10-10 00:00:00...\n",
      "Processing trade order 2019-10-11 00:00:00...\n",
      "Processing trade order 2019-10-12 00:00:00...\n",
      "Processing trade order 2019-10-13 00:00:00...\n",
      "Processing trade order 2019-10-14 00:00:00...\n",
      "Processing trade order 2019-10-15 00:00:00...\n",
      "Processing trade order 2019-10-16 00:00:00...\n",
      "Processing trade order 2019-10-17 00:00:00...\n",
      "Processing trade order 2019-10-18 00:00:00...\n",
      "Processing trade order 2019-10-19 00:00:00...\n",
      "Processing trade order 2019-10-20 00:00:00...\n",
      "Processing trade order 2019-10-21 00:00:00...\n",
      "Processing trade order 2019-10-22 00:00:00...\n",
      "Processing trade order 2019-10-23 00:00:00...\n",
      "Processing trade order 2019-10-24 00:00:00...\n",
      "Processing trade order 2019-10-25 00:00:00...\n",
      "Processing trade order 2019-10-26 00:00:00...\n",
      "Processing trade order 2019-10-27 00:00:00...\n",
      "Processing trade order 2019-10-28 00:00:00...\n",
      "Processing trade order 2019-10-29 00:00:00...\n",
      "Processing trade order 2019-10-30 00:00:00...\n",
      "Processing trade order 2019-10-31 00:00:00...\n",
      "Processing trade order 2019-11-01 00:00:00...\n",
      "Processing trade order 2019-11-02 00:00:00...\n",
      "Processing trade order 2019-11-03 00:00:00...\n",
      "Processing trade order 2019-11-04 00:00:00...\n",
      "Processing trade order 2019-11-05 00:00:00...\n",
      "Processing trade order 2019-11-06 00:00:00...\n",
      "Processing trade order 2019-11-07 00:00:00...\n",
      "Processing trade order 2019-11-08 00:00:00...\n",
      "Processing trade order 2019-11-09 00:00:00...\n",
      "Processing trade order 2019-11-10 00:00:00...\n",
      "Processing trade order 2019-11-11 00:00:00...\n",
      "Processing trade order 2019-11-12 00:00:00...\n",
      "Processing trade order 2019-11-13 00:00:00...\n",
      "Processing trade order 2019-11-14 00:00:00...\n",
      "Generating CSV for trade order 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2909: DtypeWarning: Columns (3,4,7,8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "def main():\n",
    "#---Select here the starting date\n",
    "    year = 2019\n",
    "    month = 9\n",
    "    day = 29\n",
    "#---Importing packagesfrom datetime import datetime as dt\n",
    "    from datetime import timedelta\n",
    "    import gzip\n",
    "    import glob\n",
    "    import os\n",
    "    import shutil\n",
    "    import sys\n",
    "    import time\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from math import log,sqrt\n",
    "    import gc\n",
    "\n",
    "#---Importing raw data of trade and quote\n",
    "    # https://public.bitmex.com/?prefix=data/trade/\n",
    "    endpoint = 'https://s3-eu-west-1.amazonaws.com/public.bitmex.com/data/{}/{}.csv.gz'\n",
    "    def scrape(year, date,trqu):\n",
    "        end_date = min(dt(year, 12, 31), dt.today() - timedelta(days=1))\n",
    "        end_date = dt(2019,11,14)\n",
    "        while date <= end_date:\n",
    "            date_str = date.strftime('%Y%m%d')\n",
    "            print(\"Processing {} order {}...\".format(trqu,date))\n",
    "            count = 0\n",
    "            while True:\n",
    "                r = requests.get(endpoint.format(trqu,date_str))\n",
    "                if r.status_code == 200:\n",
    "                    break\n",
    "                else:\n",
    "                    count += 1\n",
    "                    if count == 10:\n",
    "                        r.raise_for_status()\n",
    "                    print(\"Error processing {} - {}, trying again\".format(date, r.status_code))\n",
    "                    time.sleep(10)\n",
    "            with open(date_str, 'wb') as fp:\n",
    "                fp.write(r.content)\n",
    "            with gzip.open(date_str, 'rb') as fp:\n",
    "                data = fp.read()\n",
    "            with open(date_str, 'wb') as fp:\n",
    "                fp.write(data)\n",
    "            date += timedelta(days=1)\n",
    "    def merge(year,date,trqu):\n",
    "        print(\"Generating CSV for {} order {}\".format(trqu,year))\n",
    "        files = sorted(glob.glob(\"{}*\".format(year)))\n",
    "        with open(\"Bitmex_{}_{}-{}-{}.csv\".format(trqu,date.day,date.month,year), 'wb') as out:\n",
    "            first = True\n",
    "            for f in files:\n",
    "                with open(f, 'rb') as fp:\n",
    "                    if first:\n",
    "                        fp.readline()\n",
    "                        first = False\n",
    "                    shutil.copyfileobj(fp, out)\n",
    "        for f in files:\n",
    "            os.unlink(f)\n",
    "    if __name__ == '__main__':\n",
    "        if len(sys.argv) == 2:\n",
    "            # if arg is supplied must be in format YYYYMMDD\n",
    "            # will attempt to remove that file, if exists\n",
    "            # in case data is incomplete\n",
    "            year = int(sys.argv[1][:4])\n",
    "            month = int(sys.argv[1][4:6])\n",
    "            day = int(sys.argv[1][6:])\n",
    "            start = dt(year, month, day)\n",
    "            years = list(range(year, dt.now().year + 1))\n",
    "            try:\n",
    "                os.unlink(sys.argv[1])\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "        else:\n",
    "            # 2014-11-12 is the first day of data\n",
    "            start = dt(2019, month, day)\n",
    "            years = list(range(2019, dt.now().year + 1))\n",
    "        starts = [dt(year, month, day) for year in years]\n",
    "        starts[0] = start\n",
    "\n",
    "        for trqu in ['trade']:#,'quote']:\n",
    "            for year, start in zip(years, starts):\n",
    "                scrape(year, start,trqu)\n",
    "                merge(year,start,trqu)\n",
    "    gc.collect()\n",
    "    \n",
    "    from datetime import date, datetime, time, timedelta\n",
    "    chunksize=1000000\n",
    "#---Chunk Building the midprice data base\n",
    "   chunksize=1000000\n",
    "    df_chunk=pd.read_csv('Bitmex_quote_{}-{}-{}.csv'.format(start.day,start.month,start.year),names=['Time','Currency','BestBidSize','BestBidPrice','BestAskPrice','BestAskSize'],chunksize=chunksize)\n",
    "    chunk_list=[]\n",
    "    for chunk in df_chunk:\n",
    "        chunk_filter=chunk[chunk['BestAskPrice']!='askPrice']\n",
    "        chunk_filter=chunk_filter[chunk_filter['Currency']=='XBTUSD']\n",
    "        chunk_filter['BestBidPrice']=chunk_filter['BestBidPrice'].astype(float)\n",
    "        chunk_filter['BestBidSize']=chunk_filter['BestBidSize'].astype(float)\n",
    "        chunk_filter['BestAskPrice']=chunk_filter['BestAskPrice'].astype(float)\n",
    "        chunk_filter['BestAskSize']=chunk_filter['BestAskSize'].astype(float)\n",
    "        chunk_filter['MidPrice']=(chunk_filter['BestBidPrice']+chunk_filter['BestAskPrice'])/2\n",
    "        chunk_filter['Time'] = chunk_filter['Time'].str.replace('D',' ')\n",
    "        chunk_filter['Time']=pd.to_datetime(chunk_filter['Time'])\n",
    "        chunk_filter=chunk_filter.drop([\"BestAskPrice\",\"BestAskSize\",\"BestBidPrice\",\"BestBidSize\",'Currency'],axis=1)\n",
    "        chunk_filter=chunk_filter.loc[chunk_filter['MidPrice'].shift(1)!=chunk_filter['MidPrice']]\n",
    "        chunk_filter=chunk_filter.reset_index().drop('index',axis=1)\n",
    "        chunk_list.append(chunk_filter)\n",
    "    df_concat=pd.concat(chunk_list)\n",
    "    df_concat.to_csv('BTC_Midprice_{}-{}-{}.csv'.format(start.day,start.month,start.year),index = False)\n",
    "    del df_chunk\n",
    "    del chunk_list\n",
    "    del chunk_filter\n",
    "    del df_concat\n",
    "    gc.collect()\n",
    "\n",
    "#---Chunk Building trade tick data base\n",
    "    df_chunk=pd.read_csv('Bitmex_trade_{}-{}-{}.csv'.format(start.day,start.month,start.year),names=[\"Time\",\"Currency\",\"Taker Side\",\"Size\",\"Price\",\"TickDirection\",\"TradingID\",\"GrossValue\",\"HomeNotional\",\"ForeignNotional\"],chunksize=chunksize)\n",
    "    chunk_list=[]\n",
    "    for chunk in df_chunk:\n",
    "        chunk_filter=chunk[chunk['ForeignNotional']!='foreignNotional']\n",
    "        chunk_filter=chunk_filter[chunk_filter['Currency']=='XBTUSD']\n",
    "        chunk_filter=chunk_filter.drop(['Currency','TickDirection','TradingID','GrossValue','HomeNotional','ForeignNotional'],axis=1)\n",
    "        chunk_filter['Size']=chunk_filter['Size'].astype(float)\n",
    "        chunk_filter['Price']=chunk_filter['Price'].astype(float)\n",
    "        chunk_filter['Time'] = chunk_filter['Time'].str.replace('D',' ')\n",
    "        chunk_filter['Time']=pd.to_datetime(chunk_filter['Time'])\n",
    "        chunk_filter=chunk_filter.groupby(['Time','Price','Taker Side']).agg({'Size':'sum'})\n",
    "        chunk_filter=chunk_filter.reset_index()\n",
    "        chunk_filter=chunk_filter[['Time','Price','Size','Taker Side']]\n",
    "        chunk_filter=chunk_filter.replace('Sell','SELL')\n",
    "        chunk_filter=chunk_filter.replace('Buy','BUY')\n",
    "        chunk_list.append(chunk_filter)\n",
    "    df_concat2=pd.concat(chunk_list)\n",
    "    df_concat2.to_csv('BTC_Market_orders_{}-{}-{}.csv'.format(start.day,start.month,start.year),index = False)\n",
    "    del df_concat2\n",
    "    del chunk_list\n",
    "    del chunk_filter\n",
    "    del df_chunk\n",
    "    gc.collect()\n",
    "    \n",
    "#---Labelling the data\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "orders = pd.read_csv('BTC_Market_orders_23-7-2019.csv')\n",
    "orders.Time = pd.to_datetime(orders.Time)\n",
    "mask = (orders.Time < '2019-08-01')\n",
    "orders = orders.loc[mask]\n",
    "orders.to_csv('BTC_Market_orders_23-7-2019_1-8-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# raw quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "def download_raw_quotes(year, month, show_process=False):\n",
    "#---Importing packagesfrom datetime import datetime as dt\n",
    "    from datetime import timedelta\n",
    "    import gzip\n",
    "    import glob\n",
    "    import os\n",
    "    import shutil\n",
    "    import sys\n",
    "    import time\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from math import log,sqrt\n",
    "    import gc\n",
    "    \n",
    "    if 'tmp_bitmex' not in os.listdir():\n",
    "        os.mkdir('tmp_bitmex')\n",
    "    \n",
    "    def get_next_month_dt(date):\n",
    "        month = date.month\n",
    "        year = date.year\n",
    "        next_month = month % 12 + 1\n",
    "        next_year = year + month // 12\n",
    "        return dt(next_year, next_month, date.day)\n",
    "    \n",
    "\n",
    "#---Importing raw data of trade and quote\n",
    "    # https://public.bitmex.com/?prefix=data/trade/\n",
    "    endpoint = 'https://s3-eu-west-1.amazonaws.com/public.bitmex.com/data/{}/{}.csv.gz'\n",
    "    def scrape(date,trqu):\n",
    "        end_date = get_next_month_dt(date)\n",
    "        while date < end_date:\n",
    "            date_str = date.strftime('%Y%m%d')\n",
    "            if show_process:\n",
    "                print(\"Processing {} order {}...\".format(trqu,date))\n",
    "            count = 0\n",
    "            while True:\n",
    "                r = requests.get(endpoint.format(trqu,date_str))\n",
    "                if r.status_code == 200:\n",
    "                    break\n",
    "                else:\n",
    "                    count += 1\n",
    "                    if count == 10:\n",
    "                        r.raise_for_status()\n",
    "                    print(\"Error processing {} - {}, trying again\".format(date, r.status_code))\n",
    "                    time.sleep(10)\n",
    "            with open(date_str, 'wb') as fp:\n",
    "                fp.write(r.content)\n",
    "            with gzip.open(date_str, 'rb') as fp:\n",
    "                data = fp.read()\n",
    "            with open(date_str, 'wb') as fp:\n",
    "                fp.write(data)\n",
    "            date += timedelta(days=1)\n",
    "    def merge(date,trqu):\n",
    "        print(\"{} - Generating CSV for {} order {} {}\".format(dt.now(),trqu,date.month,date.year))\n",
    "        files = sorted(glob.glob(\"{}*\".format(date.strftime('%Y%m'))))\n",
    "        with open(\"D://Trading/Data/Crypto/Bitmex/raw_quotes/{}-{}.csv\".format(date.month,date.year), 'wb') as out:\n",
    "            first = True\n",
    "            for f in files:\n",
    "                with open(f, 'rb') as fp:\n",
    "                    if first:\n",
    "                        fp.readline()\n",
    "                        first = False\n",
    "                    shutil.copyfileobj(fp, out)\n",
    "        for f in files:\n",
    "            os.unlink(f)\n",
    "    if __name__ == '__main__':     \n",
    "        start = dt(year, month, 1)\n",
    "        trqu = 'quote'\n",
    "        scrape(start,trqu)\n",
    "        merge(start,trqu)\n",
    "        \n",
    "def extract_quote_symbol(symbol, year, month):\n",
    "    list_symbols = ['ADAM19', 'BCHM19', 'EOSM19', 'ETHM19', 'ETHUSD', 'LTCM19',\n",
    "                    'TRXM19', 'XBT7D_D95', 'XBT7D_U105', 'XBTM19', 'XBTU19', 'XBTUSD',\n",
    "                    'XRPM19']\n",
    "    from datetime import timedelta\n",
    "    import gzip\n",
    "    import glob\n",
    "    import os\n",
    "    import shutil\n",
    "    import sys\n",
    "    import time\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from math import log,sqrt\n",
    "    import gc\n",
    "    start = dt(year, month, 1)\n",
    "    \n",
    "    from datetime import date, datetime, time, timedelta\n",
    "    chunksize=1000000\n",
    "#---Chunk Building the midprice data base\n",
    "    chunksize=1000000\n",
    "    df_chunk=pd.read_csv('D://Trading/Data/Crypto/Bitmex/raw_quotes/{}-{}.csv'.format(start.month,start.year),\n",
    "                         names=['Time','Currency','BestBidSize','BestBidPrice','BestAskPrice','BestAskSize'],chunksize=chunksize)\n",
    "    chunk_list=[]\n",
    "    for chunk in df_chunk:\n",
    "        chunk_filter=chunk[chunk['BestAskPrice']!='askPrice']\n",
    "        chunk_filter=chunk_filter[chunk_filter['Currency']==symbol]\n",
    "        chunk_filter['BestBidPrice']=chunk_filter['BestBidPrice'].astype(float)\n",
    "        chunk_filter['BestBidSize']=chunk_filter['BestBidSize'].astype(float)\n",
    "        chunk_filter['BestAskPrice']=chunk_filter['BestAskPrice'].astype(float)\n",
    "        chunk_filter['BestAskSize']=chunk_filter['BestAskSize'].astype(float)\n",
    "        chunk_filter['MidPrice']=(chunk_filter['BestBidPrice']+chunk_filter['BestAskPrice'])/2\n",
    "        chunk_filter['Time'] = chunk_filter['Time'].str.replace('D',' ')\n",
    "        chunk_filter['Time']=pd.to_datetime(chunk_filter['Time'])\n",
    "        chunk_filter=chunk_filter.drop(['Currency'],axis=1)\n",
    "        chunk_filter=chunk_filter.loc[chunk_filter['MidPrice'].shift(1)!=chunk_filter['MidPrice']]\n",
    "        chunk_filter=chunk_filter.reset_index().drop('index',axis=1)\n",
    "        chunk_list.append(chunk_filter)\n",
    "    df_concat=pd.concat(chunk_list)\n",
    "    \n",
    "    path_folder = f'D://Trading/Data/Crypto/Bitmex/quotes/{symbol}/'\n",
    "    try:\n",
    "        os.makedirs(path_folder)\n",
    "    except:\n",
    "        pass\n",
    "    filename = '{}.pkl'.format(date.strftime('%Y-%m'))\n",
    "    df_concat.to_pickle(path_folder_folder+filename, )\n",
    "    del df_chunk\n",
    "    del chunk_list\n",
    "    del chunk_filter\n",
    "    del df_concat\n",
    "    gc.collect()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing quote order 2021-01-01 00:00:00...\n",
      "Processing quote order 2021-01-02 00:00:00...\n",
      "Processing quote order 2021-01-03 00:00:00...\n",
      "Processing quote order 2021-01-04 00:00:00...\n",
      "Processing quote order 2021-01-05 00:00:00...\n",
      "Processing quote order 2021-01-06 00:00:00...\n",
      "Processing quote order 2021-01-07 00:00:00...\n",
      "Processing quote order 2021-01-08 00:00:00...\n",
      "Processing quote order 2021-01-09 00:00:00...\n",
      "Processing quote order 2021-01-10 00:00:00...\n",
      "Processing quote order 2021-01-11 00:00:00...\n",
      "Processing quote order 2021-01-12 00:00:00...\n",
      "Processing quote order 2021-01-13 00:00:00...\n",
      "Processing quote order 2021-01-14 00:00:00...\n",
      "Processing quote order 2021-01-15 00:00:00...\n",
      "Processing quote order 2021-01-16 00:00:00...\n",
      "Processing quote order 2021-01-17 00:00:00...\n",
      "Processing quote order 2021-01-18 00:00:00...\n",
      "Processing quote order 2021-01-19 00:00:00...\n",
      "Processing quote order 2021-01-20 00:00:00...\n",
      "Processing quote order 2021-01-21 00:00:00...\n",
      "Processing quote order 2021-01-22 00:00:00...\n",
      "Processing quote order 2021-01-23 00:00:00...\n",
      "Processing quote order 2021-01-24 00:00:00...\n",
      "Processing quote order 2021-01-25 00:00:00...\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "download_raw_quotes(2021, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for year in [2019,2020,2021]:\n",
    "    for month in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "        try:\n",
    "            print(f'{dt.now()} - dl {year} {month}')\n",
    "            download_raw_quotes(year, month, show_process=False)\n",
    "        except:\n",
    "            print(f'error dl {year} {month}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADAM19', 'BCHM19', 'EOSM19', 'ETHM19', 'ETHUSD', 'LTCM19',\n",
       "       'TRXM19', 'XBT7D_D95', 'XBT7D_U105', 'XBTM19', 'XBTU19', 'XBTUSD',\n",
       "       'XRPM19', 'symbol'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "extract_quote_symbol('XBTUSD',2021, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "list_symbols = ['ADAM19', 'BCHM19', 'EOSM19', 'ETHM19', 'ETHUSD', 'LTCM19', 'TRXM19', 'XBT7D_D95', 'XBT7D_U105', 'XBTM19', 'XBTU19', 'XBTUSD', 'XRPM19']\n",
    "symbol = 'XBTUSD'\n",
    "for year in [2019,2020,2021]:\n",
    "    for month in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "        try:\n",
    "            print(f'{dt.now()} - dl {year} {month}')\n",
    "            extract_quote_symbol(symbol,2021, 1)\n",
    "        except:\n",
    "            print(f'error dl {year} {month}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# raw trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "def download_raw_trades(year, month):\n",
    "#---Importing packagesfrom datetime import datetime as dt\n",
    "    from datetime import timedelta\n",
    "    import gzip\n",
    "    import glob\n",
    "    import os\n",
    "    import shutil\n",
    "    import sys\n",
    "    import time\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from math import log,sqrt\n",
    "    import gc\n",
    "    \n",
    "    if 'tmp_bitmex' not in os.listdir():\n",
    "        os.mkdir('tmp_bitmex')\n",
    "    \n",
    "    def get_next_month_dt(date):\n",
    "        month = date.month\n",
    "        year = date.year\n",
    "        next_month = month % 12 + 1\n",
    "        next_year = year + month // 12\n",
    "        return dt(next_year, next_month, date.day)\n",
    "    \n",
    "\n",
    "#---Importing raw data of trade and quote\n",
    "    # https://public.bitmex.com/?prefix=data/trade/\n",
    "    endpoint = 'https://s3-eu-west-1.amazonaws.com/public.bitmex.com/data/{}/{}.csv.gz'\n",
    "    def scrape(date,trqu):\n",
    "        end_date = get_next_month_dt(date)\n",
    "        while date < end_date:\n",
    "            date_str = date.strftime('%Y%m%d')\n",
    "            print(\"Processing {} order {}...\".format(trqu,date))\n",
    "            count = 0\n",
    "            while True:\n",
    "                r = requests.get(endpoint.format(trqu,date_str))\n",
    "                if r.status_code == 200:\n",
    "                    break\n",
    "                else:\n",
    "                    count += 1\n",
    "                    if count == 10:\n",
    "                        r.raise_for_status()\n",
    "                    print(\"Error processing {} - {}, trying again\".format(date, r.status_code))\n",
    "                    time.sleep(10)\n",
    "            with open(date_str, 'wb') as fp:\n",
    "                fp.write(r.content)\n",
    "            with gzip.open(date_str, 'rb') as fp:\n",
    "                data = fp.read()\n",
    "            with open(date_str, 'wb') as fp:\n",
    "                fp.write(data)\n",
    "            date += timedelta(days=1)\n",
    "    def merge(date,trqu):\n",
    "        print(\"{} - Generating CSV for {} order {} {}\".format(dt.now(),trqu,date.month,date.year))\n",
    "        files = sorted(glob.glob(\"{}*\".format(date.strftime('%Y%m'))))\n",
    "        with open(\"D://Trading/Data/Crypto/Bitmex/raw_trades/{}-{}.csv\".format(date.month,date.year), 'wb') as out:\n",
    "            first = True\n",
    "            for f in files:\n",
    "                with open(f, 'rb') as fp:\n",
    "                    if first:\n",
    "                        fp.readline()\n",
    "                        first = False\n",
    "                    shutil.copyfileobj(fp, out)\n",
    "        for f in files:\n",
    "            os.unlink(f)\n",
    "    if __name__ == '__main__':     \n",
    "        start = dt(year, month, 1)\n",
    "        trqu = 'trade'\n",
    "        scrape(start,trqu)\n",
    "        merge(start,trqu)\n",
    "        \n",
    "def extract_trades_symbol(symbol, year, month):\n",
    "    list_symbols = ['ADAM19', 'BCHM19', 'EOSM19', 'ETHM19', 'ETHUSD', 'LTCM19',\n",
    "                    'TRXM19', 'XBT7D_D95', 'XBT7D_U105', 'XBTM19', 'XBTU19', 'XBTUSD',\n",
    "                    'XRPM19']\n",
    "    from datetime import timedelta\n",
    "    import gzip\n",
    "    import glob\n",
    "    import os\n",
    "    import shutil\n",
    "    import sys\n",
    "    import time\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from math import log,sqrt\n",
    "    import gc\n",
    "    start = dt(year, month, 1)\n",
    "    \n",
    "    from datetime import date, datetime, time, timedelta\n",
    "    chunksize=1000000\n",
    "    #---Chunk Building trade tick data base\n",
    "    df_chunk=pd.read_csv('D://Trading/Data/Crypto/Bitmex/raw_trades/{}-{}.csv'.format(start.month,start.year),\n",
    "                         names=[\"Time\",\"Currency\",\"Taker Side\",\"Size\",\"Price\",\"TickDirection\",\"TradingID\",\"GrossValue\",\"HomeNotional\",\"ForeignNotional\"],chunksize=chunksize)\n",
    "    chunk_list=[]\n",
    "    for chunk in df_chunk:\n",
    "        chunk_filter=chunk[chunk['ForeignNotional']!='foreignNotional']\n",
    "        chunk_filter=chunk_filter[chunk_filter['Currency']==symbol]\n",
    "        chunk_filter=chunk_filter.drop(['Currency','TickDirection','TradingID','GrossValue','HomeNotional','ForeignNotional'],axis=1)\n",
    "        chunk_filter['Size']=chunk_filter['Size'].astype(float)\n",
    "        chunk_filter['Price']=chunk_filter['Price'].astype(float)\n",
    "        chunk_filter['Time'] = chunk_filter['Time'].str.replace('D',' ')\n",
    "        chunk_filter['Time']=pd.to_datetime(chunk_filter['Time'])\n",
    "        chunk_filter=chunk_filter.groupby(['Time','Price','Taker Side']).agg({'Size':'sum'})\n",
    "        chunk_filter=chunk_filter.reset_index()\n",
    "        chunk_filter=chunk_filter[['Time','Price','Size','Taker Side']]\n",
    "        chunk_filter=chunk_filter.replace('Sell','SELL')\n",
    "        chunk_filter=chunk_filter.replace('Buy','BUY')\n",
    "        chunk_list.append(chunk_filter)\n",
    "    df_concat2=pd.concat(chunk_list)\n",
    "    \n",
    "    path_folder = f'D://Trading/Data/Crypto/Bitmex/trades/{symbol}/'\n",
    "    try:\n",
    "        os.makedirs(path_folder)\n",
    "    except:\n",
    "        pass\n",
    "    filename = '{}.pkl'.format(date.strftime('%Y-%m'))\n",
    "    df_concat2.to_pickle(path_folder_folder+filename, )    \n",
    "\n",
    "    del df_concat2\n",
    "    del chunk_list\n",
    "    del chunk_filter\n",
    "    del df_chunk\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "download_raw_trades(2021, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop raw trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for year in [2019,2020,2021]:\n",
    "    for month in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "        try:\n",
    "            print(f'{dt.now()} - dl {year} {month}')\n",
    "            download_raw_trades(year, month, show_process=False)\n",
    "        except:\n",
    "            print(f'error dl {year} {month}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exract symbol trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "extract_trades_symbol('XBTUSD',2021, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop extract symbol trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "list_symbols = ['ADAM19', 'BCHM19', 'EOSM19', 'ETHM19', 'ETHUSD', 'LTCM19', 'TRXM19', 'XBT7D_D95', 'XBT7D_U105', 'XBTM19', 'XBTU19', 'XBTUSD', 'XRPM19']\n",
    "symbol = 'XBTUSD'\n",
    "for year in [2019,2020,2021]:\n",
    "    for month in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "        try:\n",
    "            print(f'{dt.now()} - dl {year} {month}')\n",
    "            extract_trades_symbol(symbol,2021, 1)\n",
    "        except:\n",
    "            print(f'error dl {year} {month}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
